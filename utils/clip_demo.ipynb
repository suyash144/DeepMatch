{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0048,  0.0127,  0.0413,  0.0038],\n",
      "        [ 0.0319,  0.0068,  0.0119, -0.0046],\n",
      "        [-0.0079, -0.0146,  0.0433,  0.0049],\n",
      "        [ 0.0060,  0.0371,  0.0362, -0.0088]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClipLoss2D(torch.nn.Module):\n",
    "    \"\"\"CLIP (See Open AI CLIP) constrastive loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, linear=None, twin=True, pool=False, \n",
    "                 center=False, temp_tau= 1.0):\n",
    "        super().__init__()\n",
    "        self.linear = None\n",
    "        self.pool = pool\n",
    "        self.center = center\n",
    "        if linear is not None:\n",
    "            self.linear_est = torch.nn.LazyLinear(linear)\n",
    "            if twin:\n",
    "                self.linear_gt = self.linear_est\n",
    "            else:\n",
    "                self.linear_gt = torch.nn.LazyLinear(linear)\n",
    "        self.temp_tau = nn.Parameter(torch.tensor(temp_tau))\n",
    "\n",
    "    def get_scores(self, estimates: torch.Tensor, candidates: torch.Tensor):\n",
    "        \"\"\"Given estimates that is [B, C, T] and candidates\n",
    "        which is [B', C, T], return a [B, B'] matrix of scores of matching.\n",
    "        \"\"\"\n",
    "        if self.linear:\n",
    "            estimates = self.linear_est(estimates)\n",
    "            candidates = self.linear_gt(candidates)\n",
    "        if self.pool:\n",
    "            estimates = estimates.mean(dim=2, keepdim=True)\n",
    "            candidates = candidates.mean(dim=2, keepdim=True)\n",
    "        if self.center:\n",
    "            estimates = estimates - estimates.mean(dim=(1, 2), keepdim=True)\n",
    "            candidates = candidates - candidates.mean(dim=(1, 2), keepdim=True)\n",
    "\n",
    "        inv_norms = 1 / (1e-8 + candidates.norm(dim=(1, 2), p=2))\n",
    "        inv_norms_2 = 1 / (1e-8 + estimates.norm(dim=(1, 2), p=2))\n",
    "        scores = torch.einsum(\"bct,oct,b,o -> bo\", estimates, candidates, inv_norms_2, inv_norms)\n",
    "        \n",
    "        # We normalize inside the einsum, to avoid creating a copy\n",
    "        # of candidates, which can be pretty big.\n",
    "        # scores = torch.einsum(\"bct,oct,o->bo\", estimates, candidates, inv_norms)\n",
    "        # scores = torch.einsum(\"bct,bct->bc\", estimates, candidates)\n",
    "        scores = torch.einsum(\"bct,oct,b,o -> bo\", estimates, candidates, inv_norms_2, inv_norms)\n",
    "        return scores\n",
    "    \n",
    "    def get_probabilities(self, estimates, candidates):\n",
    "        \"\"\"Given estimates that is [B, C, T] and candidates\n",
    "        which is [B', C, T], return a [B, B'] matrix of probabilities of matching.\n",
    "        \"\"\"\n",
    "        scores = self.get_scores(estimates, candidates)\n",
    "        scores = scores / self.temp_tau\n",
    "        return F.softmax(scores, dim=1)\n",
    "\n",
    "    def forward(self, estimate, candidate, mask=None):\n",
    "        \"\"\"Warning: estimate and candidate are not necessarily symmetrical.\n",
    "        If estimate of shape [B, C, T] and candidate of size [B', C, T]\n",
    "        with B'>=B, the first B samples of candidate are targets, while\n",
    "        the remaining B'-B samples of candidate are only used as negatives.\n",
    "        \"\"\"\n",
    "        # assert mask.all(), \"mask is not supported for now\"\n",
    "        assert estimate.size(0) <= candidate.size(0), \"need at least as many targets as estimates\"\n",
    "        scores = self.get_probabilities(estimate, candidate)\n",
    "        target = torch.arange(len(scores), device=estimate.device)\n",
    "        return F.cross_entropy(scores, target)\n",
    "    \n",
    "clip_loss = ClipLoss2D(linear=None, twin=True, pool=False, center=False, temp_tau=1.0)\n",
    "\n",
    "estimates = torch.randn(4, 8, 82)\n",
    "candidates = torch.randn(4, 8, 82)\n",
    "scores = clip_loss.get_scores(estimates, candidates)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2552,  0.6079, -0.1632,  0.2943],\n",
      "        [-0.2991, -0.3183,  0.4228, -0.5013],\n",
      "        [-0.1480, -0.0494,  0.0910, -0.1085],\n",
      "        [-0.2797, -0.1010, -0.3935,  0.1049]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ClipLoss1D(torch.nn.Module):\n",
    "    \"\"\"CLIP (See Open AI CLIP) contrastive loss.\"\"\"\n",
    "\n",
    "    def __init__(self, linear=None, twin=True, center=False, temp_tau=1.0):\n",
    "        super().__init__()\n",
    "        self.linear = None\n",
    "        self.center = center\n",
    "        if linear is not None:\n",
    "            self.linear_est = torch.nn.LazyLinear(linear)\n",
    "            if twin:\n",
    "                self.linear_gt = self.linear_est\n",
    "            else:\n",
    "                self.linear_gt = torch.nn.LazyLinear(linear)\n",
    "        self.temp_tau = nn.Parameter(torch.tensor(temp_tau))\n",
    "\n",
    "    def get_scores(self, estimates: torch.Tensor, candidates: torch.Tensor):\n",
    "        \"\"\"Given estimates that is [B, N] and candidates which is [B', N],\n",
    "        return a [B, B'] matrix of scores of matching.\"\"\"\n",
    "        if self.linear:\n",
    "            estimates = self.linear_est(estimates)\n",
    "            candidates = self.linear_gt(candidates)\n",
    "        if self.center:\n",
    "            estimates = estimates - estimates.mean(dim=1, keepdim=True)\n",
    "            candidates = candidates - candidates.mean(dim=1, keepdim=True)\n",
    "\n",
    "        inv_norms = 1 / (1e-8 + candidates.norm(dim=1, p=2))\n",
    "        inv_norms_2 = 1 / (1e-8 + estimates.norm(dim=1, p=2))\n",
    "        # scores = torch.einsum(\"bn,on,o->bo\", estimates, candidates, inv_norms)\n",
    "        scores = torch.einsum(\"bn,on,b,o -> bo\", estimates, candidates, inv_norms_2, inv_norms)\n",
    "        return scores\n",
    "\n",
    "    def get_probabilities(self, estimates, candidates):\n",
    "        \"\"\"Given estimates that is [B, N] and candidates which is [B', N],\n",
    "        return a [B, B'] matrix of probabilities of matching.\"\"\"\n",
    "        scores = self.get_scores(estimates, candidates)\n",
    "        scores = scores / self.temp_tau\n",
    "        return F.softmax(scores, dim=1)\n",
    "\n",
    "    def forward(self, estimate, candidate):\n",
    "        \"\"\"Forward method for ClipLoss.\"\"\"\n",
    "        assert estimate.size(0) <= candidate.size(0), \"need at least as many targets as estimates\"\n",
    "        scores = self.get_probabilities(estimate, candidate)\n",
    "        target = torch.arange(len(scores), device=estimate.device)\n",
    "        return F.cross_entropy(scores, target)\n",
    "    \n",
    "\n",
    "clip_loss = ClipLoss1D(linear=None, twin=True, center=False, temp_tau=1.0)\n",
    "\n",
    "estimates = torch.randn(4, 8)\n",
    "candidates = torch.randn(4, 8)\n",
    "scores = clip_loss.get_scores(estimates, candidates)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
